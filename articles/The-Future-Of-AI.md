---
Question ? | Answer ! |
--- | --- |
writer | Jatin
Editor | Ashita
status | Review Pending
Plagiarism | None 0% [Report link](./plag_reports/plag_the_future_of_AI.pdf)
Content | The future of AI, new quantum chip
Verdict | Good Candidate. 
---

# The Future of AI
Challenges and their solutions

Artificial Intelligence is the new cool. There is so much going in the field of computing these days that it is fairly easy to get lost in all of it. But let's pause for a while and see the bigger picture here.

We started out with what we would call today ‘expert systems’.  These were systems built to augment human intelligence by processing large bodies of knowledge into straightforward decision trees.
Then emerged Machine Learning techniques like regression, neural nets, SVMs, accompanies with Big Data and Hadoop. Now we had ways to store and query these fast moving large unstructured datasets. NLP, Image recognition, Object detection were suddenly everywhere.
We gradually moved towards Deep Learning, where the output of one layer is fed as input to next layer, thus improving the efficiency of our ML model. 
These systems were good enough for Statistical Learning, just plug huge datasets to them, and they produced satisfactory results.

But AI and Deep Learning with these models have three fundamental problems.

1. Time, The amount of time needed to train a deep net like a CNN or an RNN can be weeks. 
2. Cost, Weeks of continuous computation time on hundreds of GPUs is expensive.
3. Data:  In many cases, the unavailability of labeled data in sufficient quantity simply makes the project a non-starter.

The above problems can be tackled with the approaches below.

## HPC (High-performance computing )
The current path in AI is promising. Keep following the path of Deep Neural Net architectures that we know, just make them faster and easier to access. Make better general purpose environments like TensorFlow and Microsoft’s Cognitive Toolkit (CNTK) and increase GPU utilization in larger and larger data centers. The question, much like the limits of Moore’s Law, is just how far will these improvements take us? Would we ever be able to achieve a revolution with the said path?

## (NC) Neuromorphic Computing 
Neuromorphic or Spiking Neural Networks (SNNs) has already demonstrated several dramatic improvements over our current deep learning NNs.
SNNs are based on observations about how the brains actually work, which is in fact significantly different from the way we’ve designed our deep neural nets so far. They utilize the fact that not all ‘neurons’ in our brain fire each time, therefore a single neuron from Spiking NNs could replace hundreds in a traditional deep NNs. This also makes them energy efficient.
Their ability to learn from their environment using unsupervised techniques, i.e. no tagged examples, and that too with a very few examples makes them very quick learners. They can also generalize about their environment by learning from one environment and applying it to another. 
This year at CES, Intel launched its neuromorphic chip - Loihi, which is a great feat in itself and might change the way we think about computer chips entirely. 

## (QC) Quantum Computing 
A classical bit can take 2 values, either 0 or 1. A Quantum bit or a qubit, however, uses superposition, that is, both 0 and 1 can occur at the same time within the bit with different probabilities. The thing we need to know here is that with each additional bit, the computing power of quantum computer doubles. 
According to a research report by Google, a D-Wave quantum computer outperformed the traditional desktop by 108 times, making it one hundred million times faster. This is a whole another level of processing. 
This year at CES, Intel passed a key milestone. The tech giant has unveiled a superconducting quantum test chip with 49 qubits: enough qubits to possibly enable quantum computing that begins to exceed the practical limits of modern classical computers. 
This opens up new paths to build and test Quantum Neural Nets, and replicate traditional Deep learning models with Quantum Enhanced Learning. Yet to come is pure ‘Quantum Learning’ which will use quantum effects to yield predictive results using methods that look nothing like our current techniques.

## Conclusion

Ever more than computing power, we need better models. A good model lays the foundation for future research. Neuromorphic Computing tackles this part of the problem. It aims at a model which can produce satisfactory results with very fewer data. Quantum Computing represents a path forward for strong AI and overcomes the speed and cost issues. With quantum computers, we could run simulations that were previously not possible. The use cases are limitless.
It is only time which will unveil which path we move forward, NC, QC or maybe the fusion of the two, NQC.
