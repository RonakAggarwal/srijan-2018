---
writer: Jatin Rohilla - MCA 1st year
Editor: Ashita
---

# Neuromorphic Computing

Humans are a fairly new species. But definitely the smartest one. We soon realized that evolution is a far better inventor than us, and natural selection has highlighted the best of its inventions. So we started mimicking the nature around us.

## Biomimicry
A lot of our inventions are inspired by nature.
Classics such as the echolocation used by sonars or the velcro in your laptop bag. Or the recent ones like, the earthquake-resistant water cube architecture at the Beijing Olympics, the Burj Khalifa which is inspired by a desert flower, or the 50-foot-long kingfisher beak of the bullet train. 
The applications of Biomimicry are endless. But is that all we can learn from nature?

## Neuromorphics
Let's mimic the brain. Because, why not? 
A Brain smart enough to know its own existence is definitely one of the most powerful creations of evolution. It's been a fantasy for long enough to upload the brain onto a computer. Except for this time, we managed to do it. 
In December 2017, Scientists completed the brain mapping of an earthworm known as C. elegans. They built a Connectom which is a software program with all of worm's 1000 cells, 302 neurons as well as their functions completely mapped.
The basically built a digital brain of the earthworm, then uploaded it to a robot, left it in a small to see what happens next.
Now comes the interesting part. The robot mimicked the behavior of the earthworm, navigating the room, turned back when it saw a wall, and so.
But you may say what's new in this, we have had robots capable of navigation and avoiding walls for a long time. How is this different?
The difference is, we didn't program it to avoid walls. We didn't program it to navigate the room. All we did was digitalize the worm's brain. All of this was actually done by the digital brain itself. and this was all just software with a few sensors.

# Neuromorphic Computing 
Artificial intelligence software has increasingly begun to imitate the brain. Algorithms such as Google’s automatic image-classification use networks of artificial neurons to perform complex tasks. But because the traditional computer hardware was not designed to run brain-like algorithms, these machine-learning models require much more computing power than the human brain does. 
“There must be a better way to do this because nature has figured out a better way to do this,” says Michael Schneider, a physicist at the NIST.  
Interestingly, This year at CES, Intel showcased its research in neuromorphic computing. The Tech Giant has developed a first of its kind self-learning neuromorphic chip – code-named Loihi, which uses an asynchronous Spiking Neural Network. The chip is based on a new computing paradigm inspired by how neurons work in a human brain and scrape off the traditional computing architecture consisting of CPU and memory. The chip gets smarter over time and does not need to be trained in the traditional way with a huge data set. 

The key difference between neuromorphic and traditional computing is that they process data in an analog, rather than a digital fashion. This means that instead of sending information in a series of 0/1, they vary the intensity of these signals, just like our brain’s synapses do. This means that more information can be coded into each signal by varying the intensity, drastically reducing the amount of power needed. 
This makes the chip up to 1,000 times more energy-efficient than general purpose computing required to train any neural network. The chip serves as hardware counterpart to the Deep Neural Networks and is meant to make computations faster. 

The difference between classical systems and neuromorphic ones is just like the difference between Morse code and speech. The former encodes data using just dots, and dashes, making meanings easy to understand but the message is lengthy to communicate. Speech, however, can be difficult to interpret but each individual utterance holds much more data. Thus, the latter is very efficient. 

